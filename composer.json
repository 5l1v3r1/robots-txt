{
    "name": "spatie/robots-txt",
    "description": "Determine if a page may be crawled from robots.txt and robots meta tags",
    "keywords": [
        "spatie",
        "robots-txt"
    ],
    "homepage": "https://github.com/spatie/robots-txt",
    "license": "MIT",
    "authors": [
        {
            "name": "Brent Roose",
            "email": "brent@spatie.be",
            "homepage": "https://spatie.be",
            "role": "Developer"
        }
    ],
    "require": {
        "php": "^7.1"
    },
    "require-dev": {
        "larapack/dd": "^1.0",
        "phpunit/phpunit": "^7.0"
    },
    "autoload": {
        "psr-4": {
            "Spatie\\Skeleton\\": "src"
        }
    },
    "autoload-dev": {
        "psr-4": {
            "Spatie\\Skeleton\\Tests\\": "tests"
        }
    },
    "scripts": {
        "test": "vendor/bin/phpunit",
        "test-coverage": "phpunit --coverage-html coverage"

    },
    "config": {
        "sort-packages": true
    },
    "extra": {
        "laravel": {
            "providers": [
                "Spatie\\Skeleton\\SkeletonServiceProvider"
            ],
            "aliases": {
                "Skeleton": "Spatie\\Skeleton\\SkeletonFacade"
            }
        }
    }
}
